{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KEv_JYAZgvUy",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-Levenshtein\n",
      "  Downloading python_Levenshtein-0.25.1-py3-none-any.whl (9.4 kB)\n",
      "Collecting Levenshtein==0.25.1\n",
      "  Downloading Levenshtein-0.25.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (177 kB)\n",
      "\u001b[K     |████████████████████████████████| 177 kB 607 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting rapidfuzz<4.0.0,>=3.8.0\n",
      "  Downloading rapidfuzz-3.9.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.4 MB 4.4 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: rapidfuzz, Levenshtein, python-Levenshtein\n",
      "Successfully installed Levenshtein-0.25.1 python-Levenshtein-0.25.1 rapidfuzz-3.9.7\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.8/site-packages (3.9.1)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.8/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.8/site-packages (from nltk) (4.60.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.8/site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /opt/conda/lib/python3.8/site-packages (from nltk) (2024.9.11)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.45.2-py3-none-any.whl (9.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 9.9 MB 657 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "\u001b[K     |████████████████████████████████| 436 kB 43.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (1.24.4)\n",
      "Collecting huggingface-hub<1.0,>=0.23.2\n",
      "  Downloading huggingface_hub-0.25.2-py3-none-any.whl (436 kB)\n",
      "\u001b[K     |████████████████████████████████| 436 kB 40.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from transformers) (20.9)\n",
      "Collecting tokenizers<0.21,>=0.20\n",
      "  Downloading tokenizers-0.20.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.0 MB 46.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers) (2024.9.11)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.16.1-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers) (4.60.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers) (2.25.1)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
      "\u001b[K     |████████████████████████████████| 179 kB 57.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.9.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (2023.11.17)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers) (4.0.0)\n",
      "Installing collected packages: fsspec, filelock, huggingface-hub, tokenizers, safetensors, transformers\n",
      "Successfully installed filelock-3.16.1 fsspec-2024.9.0 huggingface-hub-0.25.2 safetensors-0.4.5 tokenizers-0.20.1 transformers-4.45.2\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.8/site-packages (1.7.1+cu110)\n",
      "Collecting torch\n",
      "  Downloading torch-2.4.1-cp38-cp38-manylinux1_x86_64.whl (797.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 797.1 MB 40 kB/s  eta 0:00:012    |█▊                              | 44.3 MB 40.9 MB/s eta 0:00:19     |█████████▏                      | 227.9 MB 16.8 MB/s eta 0:00:34\n",
      "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 196.0 MB 17.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 5.9 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.8/site-packages (from torch) (4.9.0)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 121.6 MB 236 kB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 23.7 MB 17.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[K     |████████████████████████████████| 823 kB 22.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch) (2.11.3)\n",
      "Collecting nvidia-cudnn-cu12==9.1.0.70\n",
      "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 664.8 MB 29 kB/s  eta 0:00:016\n",
      "\u001b[?25hCollecting sympy\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 6.2 MB 5.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch) (2024.9.0)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 410.6 MB 11.3 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.20.5\n",
      "  Downloading nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 176.2 MB 322 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 14.1 MB 5.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 56.5 MB 10.9 MB/s eta 0:00:01    |██████████████████▏             | 32.0 MB 4.7 MB/s eta 0:00:06\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch) (2.5.1)\n",
      "Collecting triton==3.0.0\n",
      "  Downloading triton-3.0.0-1-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 209.4 MB 10.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch) (3.16.1)\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 124.2 MB 5.2 MB/s eta 0:00:011\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (19.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 19.7 MB 4.6 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch) (1.1.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.8/site-packages (from networkx->torch) (4.4.2)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[K     |████████████████████████████████| 536 kB 10.1 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-cusparse-cu12, nvidia-cublas-cu12, mpmath, triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusolver-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, torch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.7.1+cu110\n",
      "    Uninstalling torch-1.7.1+cu110:\n",
      "      Successfully uninstalled torch-1.7.1+cu110\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchvision 0.8.2+cu110 requires torch==1.7.1, but you have torch 2.4.1 which is incompatible.\u001b[0m\n",
      "Successfully installed mpmath-1.3.0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.6.77 nvidia-nvtx-cu12-12.1.105 sympy-1.13.3 torch-2.4.1 triton-3.0.0\n",
      "Collecting natten\n",
      "  Downloading natten-0.17.1.tar.gz (10.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 10.8 MB 1.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from natten) (20.9)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from natten) (2.4.1)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (2.5.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (3.16.1)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (12.1.105)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (2.11.3)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (12.1.105)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (2024.9.0)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (12.1.3.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (12.1.0.106)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (11.4.5.107)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (12.1.105)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (11.0.2.54)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (2.20.5)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (4.9.0)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (10.3.2.106)\n",
      "Requirement already satisfied: triton==3.0.0 in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (3.0.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=2.0.0->natten) (1.13.3)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12 in /opt/conda/lib/python3.8/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->natten) (12.6.77)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=2.0.0->natten) (1.1.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /opt/conda/lib/python3.8/site-packages (from networkx->torch>=2.0.0->natten) (4.4.2)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->natten) (2.4.7)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=2.0.0->natten) (1.3.0)\n",
      "Building wheels for collected packages: natten\n",
      "  Building wheel for natten (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/conda/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-lgb5p0um\n",
      "       cwd: /tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/\n",
      "  Complete output (93 lines):\n",
      "  Building NATTEN with CUDA 121\n",
      "  Building NATTEN for SM: 8.6\n",
      "  Number of workers: 8\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.linux-x86_64-3.8\n",
      "  creating build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/ops.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/types.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/flops.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/na1d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/nested.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/functional.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/na3d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/context.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/natten3d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/__init__.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/na2d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/natten1d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  copying src/natten/natten2d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "  creating build/lib.linux-x86_64-3.8/natten/utils\n",
      "  copying src/natten/utils/log.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "  copying src/natten/utils/misc.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "  copying src/natten/utils/tensor.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "  copying src/natten/utils/__init__.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "  copying src/natten/utils/testing.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "  copying src/natten/utils/checks.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "  creating build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "  copying src/natten/autotuner/fna_forward.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "  copying src/natten/autotuner/misc.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "  copying src/natten/autotuner/__init__.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "  copying src/natten/autotuner/fna_backward.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "  creating build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  copying src/natten/autotuner/configs/fna_backward_128x64.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  copying src/natten/autotuner/configs/__init__.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  copying src/natten/autotuner/configs/fna_forward_64x64.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  copying src/natten/autotuner/configs/fna_forward_64x128.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  copying src/natten/autotuner/configs/fna_backward_64x64.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  copying src/natten/autotuner/configs/fna_forward_32x128.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  copying src/natten/autotuner/configs/fna_backward_128x128.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "  running build_ext\n",
      "  Traceback (most recent call last):\n",
      "    File \"/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py\", line 162, in build_extension\n",
      "      subprocess.check_output([\"cmake\", \"--version\"])\n",
      "    File \"/opt/conda/lib/python3.8/subprocess.py\", line 415, in check_output\n",
      "      return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "    File \"/opt/conda/lib/python3.8/subprocess.py\", line 493, in run\n",
      "      with Popen(*popenargs, **kwargs) as process:\n",
      "    File \"/opt/conda/lib/python3.8/subprocess.py\", line 858, in __init__\n",
      "      self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "    File \"/opt/conda/lib/python3.8/subprocess.py\", line 1706, in _execute_child\n",
      "      raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "  FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "  \n",
      "  During handling of the above exception, another exception occurred:\n",
      "  \n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 1, in <module>\n",
      "    File \"/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py\", line 243, in <module>\n",
      "      setup(\n",
      "    File \"/opt/conda/lib/python3.8/site-packages/setuptools/__init__.py\", line 163, in setup\n",
      "      return distutils.core.setup(**attrs)\n",
      "    File \"/opt/conda/lib/python3.8/distutils/core.py\", line 148, in setup\n",
      "      dist.run_commands()\n",
      "    File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 966, in run_commands\n",
      "      self.run_command(cmd)\n",
      "    File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/opt/conda/lib/python3.8/site-packages/wheel/bdist_wheel.py\", line 299, in run\n",
      "      self.run_command('build')\n",
      "    File \"/opt/conda/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/opt/conda/lib/python3.8/distutils/command/build.py\", line 135, in run\n",
      "      self.run_command(cmd_name)\n",
      "    File \"/opt/conda/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n",
      "      self.distribution.run_command(command)\n",
      "    File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "      cmd_obj.run()\n",
      "    File \"/opt/conda/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 87, in run\n",
      "      _build_ext.run(self)\n",
      "    File \"/opt/conda/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\n",
      "      self.build_extensions()\n",
      "    File \"/opt/conda/lib/python3.8/distutils/command/build_ext.py\", line 449, in build_extensions\n",
      "      self._build_extensions_serial()\n",
      "    File \"/opt/conda/lib/python3.8/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\n",
      "      self.build_extension(ext)\n",
      "    File \"/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py\", line 164, in build_extension\n",
      "      raise RuntimeError(\"Cannot find CMake executable\")\n",
      "  RuntimeError: Cannot find CMake executable\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for natten\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for natten\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to build natten\n",
      "Installing collected packages: natten\n",
      "    Running setup.py install for natten ... \u001b[?25lerror\n",
      "\u001b[31m    ERROR: Command errored out with exit status 1:\n",
      "     command: /opt/conda/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-i5tkfjmw/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/include/python3.8/natten\n",
      "         cwd: /tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/\n",
      "    Complete output (95 lines):\n",
      "    Building NATTEN with CUDA 121\n",
      "    Building NATTEN for SM: 8.6\n",
      "    Number of workers: 8\n",
      "    running install\n",
      "    running build\n",
      "    running build_py\n",
      "    creating build\n",
      "    creating build/lib.linux-x86_64-3.8\n",
      "    creating build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/ops.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/types.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/flops.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/na1d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/nested.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/functional.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/na3d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/context.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/natten3d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/__init__.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/na2d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/natten1d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    copying src/natten/natten2d.py -> build/lib.linux-x86_64-3.8/natten\n",
      "    creating build/lib.linux-x86_64-3.8/natten/utils\n",
      "    copying src/natten/utils/log.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "    copying src/natten/utils/misc.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "    copying src/natten/utils/tensor.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "    copying src/natten/utils/__init__.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "    copying src/natten/utils/testing.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "    copying src/natten/utils/checks.py -> build/lib.linux-x86_64-3.8/natten/utils\n",
      "    creating build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "    copying src/natten/autotuner/fna_forward.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "    copying src/natten/autotuner/misc.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "    copying src/natten/autotuner/__init__.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "    copying src/natten/autotuner/fna_backward.py -> build/lib.linux-x86_64-3.8/natten/autotuner\n",
      "    creating build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    copying src/natten/autotuner/configs/fna_backward_128x64.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    copying src/natten/autotuner/configs/__init__.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    copying src/natten/autotuner/configs/fna_forward_64x64.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    copying src/natten/autotuner/configs/fna_forward_64x128.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    copying src/natten/autotuner/configs/fna_backward_64x64.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    copying src/natten/autotuner/configs/fna_forward_32x128.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    copying src/natten/autotuner/configs/fna_backward_128x128.py -> build/lib.linux-x86_64-3.8/natten/autotuner/configs\n",
      "    running build_ext\n",
      "    Traceback (most recent call last):\n",
      "      File \"/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py\", line 162, in build_extension\n",
      "        subprocess.check_output([\"cmake\", \"--version\"])\n",
      "      File \"/opt/conda/lib/python3.8/subprocess.py\", line 415, in check_output\n",
      "        return run(*popenargs, stdout=PIPE, timeout=timeout, check=True,\n",
      "      File \"/opt/conda/lib/python3.8/subprocess.py\", line 493, in run\n",
      "        with Popen(*popenargs, **kwargs) as process:\n",
      "      File \"/opt/conda/lib/python3.8/subprocess.py\", line 858, in __init__\n",
      "        self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "      File \"/opt/conda/lib/python3.8/subprocess.py\", line 1706, in _execute_child\n",
      "        raise child_exception_type(errno_num, err_msg, err_filename)\n",
      "    FileNotFoundError: [Errno 2] No such file or directory: 'cmake'\n",
      "    \n",
      "    During handling of the above exception, another exception occurred:\n",
      "    \n",
      "    Traceback (most recent call last):\n",
      "      File \"<string>\", line 1, in <module>\n",
      "      File \"/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py\", line 243, in <module>\n",
      "        setup(\n",
      "      File \"/opt/conda/lib/python3.8/site-packages/setuptools/__init__.py\", line 163, in setup\n",
      "        return distutils.core.setup(**attrs)\n",
      "      File \"/opt/conda/lib/python3.8/distutils/core.py\", line 148, in setup\n",
      "        dist.run_commands()\n",
      "      File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 966, in run_commands\n",
      "        self.run_command(cmd)\n",
      "      File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/opt/conda/lib/python3.8/site-packages/setuptools/command/install.py\", line 61, in run\n",
      "        return orig.install.run(self)\n",
      "      File \"/opt/conda/lib/python3.8/distutils/command/install.py\", line 545, in run\n",
      "        self.run_command('build')\n",
      "      File \"/opt/conda/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n",
      "        self.distribution.run_command(command)\n",
      "      File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/opt/conda/lib/python3.8/distutils/command/build.py\", line 135, in run\n",
      "        self.run_command(cmd_name)\n",
      "      File \"/opt/conda/lib/python3.8/distutils/cmd.py\", line 313, in run_command\n",
      "        self.distribution.run_command(command)\n",
      "      File \"/opt/conda/lib/python3.8/distutils/dist.py\", line 985, in run_command\n",
      "        cmd_obj.run()\n",
      "      File \"/opt/conda/lib/python3.8/site-packages/setuptools/command/build_ext.py\", line 87, in run\n",
      "        _build_ext.run(self)\n",
      "      File \"/opt/conda/lib/python3.8/distutils/command/build_ext.py\", line 340, in run\n",
      "        self.build_extensions()\n",
      "      File \"/opt/conda/lib/python3.8/distutils/command/build_ext.py\", line 449, in build_extensions\n",
      "        self._build_extensions_serial()\n",
      "      File \"/opt/conda/lib/python3.8/distutils/command/build_ext.py\", line 474, in _build_extensions_serial\n",
      "        self.build_extension(ext)\n",
      "      File \"/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py\", line 164, in build_extension\n",
      "        raise RuntimeError(\"Cannot find CMake executable\")\n",
      "    RuntimeError: Cannot find CMake executable\n",
      "    ----------------------------------------\u001b[0m\n",
      "\u001b[31mERROR: Command errored out with exit status 1: /opt/conda/bin/python3.8 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-install-jz7z28qx/natten_662703da11244baf910b26fdfe641902/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' install --record /tmp/pip-record-i5tkfjmw/install-record.txt --single-version-externally-managed --compile --install-headers /opt/conda/include/python3.8/natten Check the logs for full command output.\u001b[0m\n",
      "\u001b[?25hCollecting jupyter\n",
      "  Downloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
      "Collecting ipywidgets\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "\u001b[K     |████████████████████████████████| 139 kB 579 kB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyterlab-widgets~=3.0.12\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 214 kB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.0.5)\n",
      "Collecting comm>=0.1.3\n",
      "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
      "Collecting widgetsnbextension~=4.0.12\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.3 MB 7.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: ipython>=6.1.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.22.0)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.18)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (49.6.0.post20210108)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.2)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab in /opt/conda/lib/python3.8/site-packages (from jupyter) (3.0.12)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.0.7)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.8/site-packages (from jupyter) (5.5.3)\n",
      "Requirement already satisfied: notebook in /opt/conda/lib/python3.8/site-packages (from jupyter) (6.3.0)\n",
      "Collecting jupyter-console\n",
      "  Downloading jupyter_console-6.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (6.1.12)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel->jupyter) (4.7.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel->jupyter) (22.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel->jupyter) (2.8.1)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.8/site-packages (from python-dateutil>=2.1->jupyter-client->ipykernel->jupyter) (1.15.0)\n",
      "Collecting prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0\n",
      "  Downloading prompt_toolkit-3.0.48-py3-none-any.whl (386 kB)\n",
      "\u001b[K     |████████████████████████████████| 386 kB 94.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jupyter-core>=4.6.0\n",
      "  Downloading jupyter_core-5.7.2-py3-none-any.whl (28 kB)\n",
      "Collecting jupyter-client\n",
      "  Downloading jupyter_client-8.6.3-py3-none-any.whl (106 kB)\n",
      "\u001b[K     |████████████████████████████████| 106 kB 87.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipykernel\n",
      "  Downloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 99.8 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting traitlets>=4.3.1\n",
      "  Downloading traitlets-5.14.3-py3-none-any.whl (85 kB)\n",
      "\u001b[K     |████████████████████████████████| 85 kB 2.0 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting ipython>=6.1.0\n",
      "  Downloading ipython-8.12.3-py3-none-any.whl (798 kB)\n",
      "\u001b[K     |████████████████████████████████| 798 kB 63.5 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: nest-asyncio in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (1.5.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from ipykernel->jupyter) (20.9)\n",
      "Collecting psutil\n",
      "  Downloading psutil-6.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (290 kB)\n",
      "\u001b[K     |████████████████████████████████| 290 kB 88.4 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting debugpy>=1.6.5\n",
      "  Downloading debugpy-1.8.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 72.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyzmq>=13\n",
      "  Downloading pyzmq-26.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (862 kB)\n",
      "\u001b[K     |████████████████████████████████| 862 kB 43.2 MB/s eta 0:00:01     |██████████████████▎             | 491 kB 43.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting matplotlib-inline>=0.1\n",
      "  Downloading matplotlib_inline-0.1.7-py3-none-any.whl (9.9 kB)\n",
      "Collecting stack-data\n",
      "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Collecting python-dateutil>=2.1\n",
      "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
      "\u001b[K     |████████████████████████████████| 229 kB 60.2 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tornado>=4.2\n",
      "  Downloading tornado-6.4.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (436 kB)\n",
      "\u001b[K     |████████████████████████████████| 436 kB 53.9 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting importlib-metadata>=4.8.3\n",
      "  Downloading importlib_metadata-8.5.0-py3-none-any.whl (26 kB)\n",
      "Collecting zipp>=3.20\n",
      "  Downloading zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.8/site-packages (from jupyter-core>=4.6.0->jupyter-client->ipykernel->jupyter) (4.1.0)\n",
      "Requirement already satisfied: jupyter-packaging~=0.7.3 in /opt/conda/lib/python3.8/site-packages (from jupyterlab->jupyter) (0.7.12)\n",
      "Requirement already satisfied: nbclassic~=0.2 in /opt/conda/lib/python3.8/site-packages (from jupyterlab->jupyter) (0.2.7)\n",
      "Requirement already satisfied: jupyter-server~=1.4 in /opt/conda/lib/python3.8/site-packages (from jupyterlab->jupyter) (1.6.1)\n",
      "Requirement already satisfied: jupyterlab-server~=2.3 in /opt/conda/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.4.0)\n",
      "Requirement already satisfied: jinja2>=2.10 in /opt/conda/lib/python3.8/site-packages (from jupyterlab->jupyter) (2.11.3)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2>=2.10->jupyterlab->jupyter) (1.1.1)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.8/site-packages (from jupyter-server~=1.4->jupyterlab->jupyter) (5.1.3)\n",
      "Requirement already satisfied: anyio>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from jupyter-server~=1.4->jupyterlab->jupyter) (2.2.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.8/site-packages (from jupyter-server~=1.4->jupyterlab->jupyter) (20.1.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.8/site-packages (from jupyter-server~=1.4->jupyterlab->jupyter) (1.5.0)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from jupyter-server~=1.4->jupyterlab->jupyter) (0.10.1)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.8/site-packages (from jupyter-server~=1.4->jupyterlab->jupyter) (0.9.4)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.8/site-packages (from anyio>=2.0.2->jupyter-server~=1.4->jupyterlab->jupyter) (2.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.8/site-packages (from anyio>=2.0.2->jupyter-server~=1.4->jupyterlab->jupyter) (1.2.0)\n",
      "Requirement already satisfied: json5 in /opt/conda/lib/python3.8/site-packages (from jupyterlab-server~=2.3->jupyterlab->jupyter) (0.9.5)\n",
      "Requirement already satisfied: babel in /opt/conda/lib/python3.8/site-packages (from jupyterlab-server~=2.3->jupyterlab->jupyter) (2.9.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from jupyterlab-server~=2.3->jupyterlab->jupyter) (2.25.1)\n",
      "Requirement already satisfied: jsonschema>=3.0.1 in /opt/conda/lib/python3.8/site-packages (from jupyterlab-server~=2.3->jupyterlab->jupyter) (3.2.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab->jupyter) (0.17.3)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema>=3.0.1->jupyterlab-server~=2.3->jupyterlab->jupyter) (20.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from argon2-cffi->jupyter-server~=1.4->jupyterlab->jupyter) (1.14.5)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.8/site-packages (from cffi>=1.0.0->argon2-cffi->jupyter-server~=1.4->jupyterlab->jupyter) (2.20)\n",
      "Requirement already satisfied: pytz>=2015.7 in /opt/conda/lib/python3.8/site-packages (from babel->jupyterlab-server~=2.3->jupyterlab->jupyter) (2021.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.8.4)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.3)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (3.3.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (1.4.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.4.4)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.1.2)\n",
      "Requirement already satisfied: nbclient<0.6.0,>=0.5.0 in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.5.3)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->jupyter) (0.7.1)\n",
      "Requirement already satisfied: async-generator in /opt/conda/lib/python3.8/site-packages (from nbclient<0.6.0,>=0.5.0->nbconvert->jupyter) (1.10)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->jupyter) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->ipykernel->jupyter) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->jupyterlab-server~=2.3->jupyterlab->jupyter) (1.26.4)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.8/site-packages (from requests->jupyterlab-server~=2.3->jupyterlab->jupyter) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->jupyterlab-server~=2.3->jupyterlab->jupyter) (2023.11.17)\n",
      "Collecting pure-eval\n",
      "  Downloading pure_eval-0.2.3-py3-none-any.whl (11 kB)\n",
      "Collecting executing>=1.2.0\n",
      "  Downloading executing-2.1.0-py2.py3-none-any.whl (25 kB)\n",
      "Collecting asttokens>=2.1.0\n",
      "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
      "Installing collected packages: zipp, traitlets, tornado, pyzmq, python-dateutil, pure-eval, jupyter-core, importlib-metadata, executing, asttokens, stack-data, prompt-toolkit, matplotlib-inline, jupyter-client, psutil, ipython, debugpy, comm, ipykernel, widgetsnbextension, jupyterlab-widgets, jupyter-console, ipywidgets, jupyter\n",
      "  Attempting uninstall: zipp\n",
      "    Found existing installation: zipp 3.4.1\n",
      "    Uninstalling zipp-3.4.1:\n",
      "      Successfully uninstalled zipp-3.4.1\n",
      "  Attempting uninstall: traitlets\n",
      "    Found existing installation: traitlets 5.0.5\n",
      "    Uninstalling traitlets-5.0.5:\n",
      "      Successfully uninstalled traitlets-5.0.5\n",
      "  Attempting uninstall: tornado\n",
      "    Found existing installation: tornado 6.1\n",
      "    Uninstalling tornado-6.1:\n",
      "      Successfully uninstalled tornado-6.1\n",
      "  Attempting uninstall: pyzmq\n",
      "    Found existing installation: pyzmq 22.0.3\n",
      "    Uninstalling pyzmq-22.0.3:\n",
      "      Successfully uninstalled pyzmq-22.0.3\n",
      "  Attempting uninstall: python-dateutil\n",
      "    Found existing installation: python-dateutil 2.8.1\n",
      "    Uninstalling python-dateutil-2.8.1:\n",
      "      Successfully uninstalled python-dateutil-2.8.1\n",
      "  Attempting uninstall: jupyter-core\n",
      "    Found existing installation: jupyter-core 4.7.1\n",
      "    Uninstalling jupyter-core-4.7.1:\n",
      "      Successfully uninstalled jupyter-core-4.7.1\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 3.10.1\n",
      "    Uninstalling importlib-metadata-3.10.1:\n",
      "      Successfully uninstalled importlib-metadata-3.10.1\n",
      "  Attempting uninstall: prompt-toolkit\n",
      "    Found existing installation: prompt-toolkit 3.0.18\n",
      "    Uninstalling prompt-toolkit-3.0.18:\n",
      "      Successfully uninstalled prompt-toolkit-3.0.18\n",
      "  Attempting uninstall: jupyter-client\n",
      "    Found existing installation: jupyter-client 6.1.12\n",
      "    Uninstalling jupyter-client-6.1.12:\n",
      "      Successfully uninstalled jupyter-client-6.1.12\n",
      "  Attempting uninstall: ipython\n",
      "    Found existing installation: ipython 7.22.0\n",
      "    Uninstalling ipython-7.22.0:\n",
      "      Successfully uninstalled ipython-7.22.0\n",
      "  Attempting uninstall: ipykernel\n",
      "    Found existing installation: ipykernel 5.5.3\n",
      "    Uninstalling ipykernel-5.5.3:\n",
      "      Successfully uninstalled ipykernel-5.5.3\n",
      "Successfully installed asttokens-2.4.1 comm-0.2.2 debugpy-1.8.7 executing-2.1.0 importlib-metadata-8.5.0 ipykernel-6.29.5 ipython-8.12.3 ipywidgets-8.1.5 jupyter-1.1.1 jupyter-client-8.6.3 jupyter-console-6.6.3 jupyter-core-5.7.2 jupyterlab-widgets-3.0.13 matplotlib-inline-0.1.7 prompt-toolkit-3.0.48 psutil-6.0.0 pure-eval-0.2.3 python-dateutil-2.9.0.post0 pyzmq-26.2.0 stack-data-0.6.3 tornado-6.4.1 traitlets-5.14.3 widgetsnbextension-4.0.13 zipp-3.20.2\n"
     ]
    }
   ],
   "source": [
    "!pip install python-Levenshtein\n",
    "!pip install nltk\n",
    "!pip install --upgrade transformers\n",
    "!pip install --upgrade torch\n",
    "!pip install natten\n",
    "!pip install --upgrade jupyter ipywidgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "GSlEzUgvg2Np"
   },
   "outputs": [],
   "source": [
    "from Levenshtein import distance, ratio\n",
    "\n",
    "import enum\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import requests\n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UG7zUHedg9pO"
   },
   "outputs": [],
   "source": [
    "# Словарь омоглифов\n",
    "with open(\"data/homoglyphs.pkl\", \"rb\") as file:\n",
    "    glyphs = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "SAfZpoLZhEPZ"
   },
   "outputs": [],
   "source": [
    "class AvailableCorrectors(enum.Enum):\n",
    "\n",
    "    sage_fredt5_large = \"ai-forever/sage-fredt5-large\"\n",
    "    sage_fredt5_distilled_95m = \"ai-forever/sage-fredt5-distilled-95m\"\n",
    "    sage_m2m100_1B = \"ai-forever/sage-m2m100-1.2B\"\n",
    "    sage_mt5_large = \"ai-forever/sage-mt5-large\"\n",
    "\n",
    "    m2m100_1B = \"ai-forever/RuM2M100-1.2B\"\n",
    "    m2m100_418M = \"ai-forever/RuM2M100-418M\"\n",
    "    fred_large = \"ai-forever/FRED-T5-large-spell\"\n",
    "    ent5_large = \"ai-forever/T5-large-spell\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nWDpqUOXhG1R"
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.02152705192565918,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "config.json",
       "rate": null,
       "total": 789,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34a8751313c34c69a18df1a4b7b1fa74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.0168459415435791,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "model.safetensors",
       "rate": null,
       "total": 382561704,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a45941d35fdd4d079e39c77499b63d8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/383M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016773223876953125,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "generation_config.json",
       "rate": null,
       "total": 184,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97424e53637644ada07022399592563f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.016097307205200195,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "tokenizer_config.json",
       "rate": null,
       "total": 20309,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a082e3f37a545d891ef1af1d3411545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/20.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01647019386291504,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "vocab.json",
       "rate": null,
       "total": 1813640,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82dcab77e2bb4f31bed0d20deb755c49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.81M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01279449462890625,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "merges.txt",
       "rate": null,
       "total": 1270925,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddc22f607806430a85132c6a7c5baf40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.27M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.017718076705932617,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "added_tokens.json",
       "rate": null,
       "total": 2718,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a31ddd65892c4c7ca7ec8f039648528c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/2.72k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/json": {
       "ascii": false,
       "bar_format": null,
       "colour": null,
       "elapsed": 0.01697516441345215,
       "initial": 0,
       "n": 0,
       "ncols": null,
       "nrows": null,
       "postfix": null,
       "prefix": "special_tokens_map.json",
       "rate": null,
       "total": 689,
       "unit": "B",
       "unit_divisor": 1000,
       "unit_scale": true
      },
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3a5929fabab4383a0a6a2550de6395c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/689 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "path_to_model = AvailableCorrectors.sage_fredt5_distilled_95m.value\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained(path_to_model)\n",
    "tokenizer = AutoTokenizer.from_pretrained(path_to_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "tKh7v5HihJP-"
   },
   "outputs": [],
   "source": [
    "with open('data/dictionary_dataset_balanced_2m.pkl', 'rb') as f:\n",
    "  dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50364"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LKwm_o1AhR3o"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50568, 512)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = list(set().union(*glyphs.values()))\n",
    "tokens = set(tokens) - set(tokenizer.vocab.keys())\n",
    "tokenizer.add_tokens(list(tokens))\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['PERTAINING ŢỎ 1ỴСÀṈΤⱧƦỌṖỾ.', 'PERTAINING TO LYCANTHROPY.'],\n",
       " ['TO MAKE A RING AROUND BY CUTTING AWAY THE BARK; TO GIRDLE; AS  TΟ ṞꞮṆꞬ ΒṚẠṄĊꞪẸȘ ƠŖ ⱤỎỌṪṠ.',\n",
       "  'TO MAKE A RING AROUND BY CUTTING AWAY THE BARK; TO GIRDLE; AS  TO RING BRANCHES OR ROOTS.'],\n",
       " ['A DOOR IN THE BACK PART OF A BUILDING; HENCE  AN INDIRECT WĄУ.',\n",
       "  'A DOOR IN THE BACK PART OF A BUILDING; HENCE  AN INDIRECT WAY.'],\n",
       " ['OF FREEMAŃ', 'OF FREEMAN'],\n",
       " ['A ɓę1ỉẹṿėŗ ìп ḿȯņíѕɱ.', 'A believer in monism.']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WizzXwxUhX2a"
   },
   "outputs": [],
   "source": [
    "# prefix = \"fix homoglyphs: \"\n",
    "# encoding_x = tokenizer([prefix + sentence for sentence in [x[0] for x in dataset]], return_tensors='pt', padding='longest')\n",
    "# attention_mask = encoding_x.attention_mask\n",
    "# X_input_ids = encoding_x.input_ids\n",
    "# y_input_ids = tokenizer([x[1] for x in dataset], return_tensors='pt', padding='longest').input_ids\n",
    "# y_input_ids[y_input_ids == tokenizer.pad_token_id] = -100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RY-AH57pheJk"
   },
   "outputs": [],
   "source": [
    "# train_size = int(0.8*dataset.shape[0])\n",
    "# test_size = int(0.1*dataset.shape[0])\n",
    "\n",
    "# x_train = X_input_ids[:train_size]\n",
    "# train_mask = attention_mask[:train_size]\n",
    "# y_train = y_input_ids[:train_size]\n",
    "\n",
    "# x_valid = X_input_ids[train_size:train_size + test_size]\n",
    "# valid_mask = attention_mask[train_size:train_size + test_size]\n",
    "# y_valid = y_input_ids[train_size:train_size + test_size]\n",
    "\n",
    "# x_test = dataset[train_size + test_size:, 0]\n",
    "# y_test = dataset[train_size + test_size:, 1]\n",
    "\n",
    "# x_train.shape, x_valid.shape, x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1774512, 221814, 221814)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_size = int(0.8*len(dataset))\n",
    "test_size = int(0.1*len(dataset))\n",
    "\n",
    "X = [x[0] for x in dataset]\n",
    "y = [x[1] for x in dataset]\n",
    "\n",
    "x_train = X[:train_size]\n",
    "y_train = y[:train_size]\n",
    "\n",
    "x_valid = X[train_size:train_size + test_size]\n",
    "y_valid = y[train_size:train_size + test_size]\n",
    "\n",
    "x_test = X[train_size + test_size:]\n",
    "y_test = y[train_size + test_size:]\n",
    "\n",
    "len(x_train), len(x_valid), len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QZHD1ELlhjCW"
   },
   "outputs": [],
   "source": [
    "class HomoglyphDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.X[index], self.y[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "BCO_FLPDhlXx"
   },
   "outputs": [],
   "source": [
    "class M2T():\n",
    "  def __init__(self, device, dataset,\n",
    "               model, tokenizer, optimizer, prefix):\n",
    "\n",
    "    self.device = device\n",
    "    self.dataset = dataset\n",
    "    self.model = model.to(self.device)\n",
    "    self.tokenizer = tokenizer\n",
    "    self.optimizer = optimizer\n",
    "    self.prefix = prefix\n",
    "\n",
    "    self.best_model = copy.deepcopy(model)\n",
    "    self.train_loss = []\n",
    "    self.val_loss = []\n",
    "    self.best_val_loss = float('inf')\n",
    "    self.best_epoch = 0\n",
    "\n",
    "  def plot_losses(self):\n",
    "    c_iter = range(len(self.train_loss))\n",
    "\n",
    "    fig = plt.figure(figsize=(15, 7), dpi=80)\n",
    "    ax = fig.gca()\n",
    "    ax.set_xticks(c_iter)\n",
    "    plt.plot(c_iter, self.train_loss, color='orange', label='train_loss')\n",
    "    plt.plot(c_iter, self.val_loss, color='blue', label='val_loss')\n",
    "\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Losses')\n",
    "    plt.savefig('losses.png')\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "  def fit(self, x_train, y_train, x_train_val, y_train_val, epochs, learning_rate, batch_size, early_stopping_patience):\n",
    "\n",
    "    self.model.to(self.device)\n",
    "    optimizer = self.optimizer(self.model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train = self.dataset(x_train, y_train)\n",
    "    val = self.dataset(x_train_val, y_train_val)\n",
    "\n",
    "    train = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
    "    val = DataLoader(val, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    space = '-'*63\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "      mean_loss = 0\n",
    "      batch_n = 0\n",
    "      self.model.train(True)\n",
    "\n",
    "      pbar_train = tqdm(train, desc=f'Epoch: {epoch + 1}/{epochs}')\n",
    "\n",
    "      for x_train, y_train in pbar_train:\n",
    "        x = tokenizer([prefix + x for x in x_train], return_tensors='pt', padding='longest').to(self.device)\n",
    "        y = tokenizer(y_train, return_tensors='pt', padding='longest').to(self.device)\n",
    "\n",
    "        loss = self.model(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            return_dict=True\n",
    "        ).loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        mean_loss += loss.item()\n",
    "        batch_n += 1\n",
    "        pbar_train.set_postfix(loss_train=round(mean_loss/batch_n, 3), refresh=True)\n",
    "\n",
    "      mean_loss /= batch_n\n",
    "      self.train_loss.append(mean_loss)\n",
    "\n",
    "      self.model.eval()\n",
    "      mean_loss = 0\n",
    "      batch_n = 0\n",
    "      with torch.no_grad():\n",
    "        for x_train_val, y_train_val in val:\n",
    "          x = tokenizer([prefix + x for x in x_train_val], return_tensors='pt', padding='longest').to(self.device)\n",
    "          y = tokenizer(y_train_val, return_tensors='pt', padding='longest').to(self.device)\n",
    "\n",
    "          loss = self.model(\n",
    "            input_ids=x.input_ids,\n",
    "            attention_mask=x.attention_mask,\n",
    "            labels=y.input_ids,\n",
    "            return_dict=True\n",
    "          ).loss\n",
    "\n",
    "          mean_loss += loss.item()\n",
    "          batch_n += 1\n",
    "\n",
    "      mean_loss /= batch_n\n",
    "      self.val_loss.append(mean_loss)\n",
    "\n",
    "      print(f'{space}loss_valid={round(mean_loss, 3)}')\n",
    "\n",
    "      if mean_loss < self.best_val_loss:\n",
    "        self.best_epoch = epoch\n",
    "        self.best_val_loss = mean_loss\n",
    "        self.best_model = copy.deepcopy(model)\n",
    "        print('^'*32 + 'new best model' + '^'*32)\n",
    "        print()\n",
    "      elif epoch - self.best_epoch > early_stopping_patience:\n",
    "        print(f'Model has not improved in the last {early_stopping_patience} epochs. Break.')\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "XYc0oPf1hmMN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "epochs = 10\n",
    "early_stop = 10\n",
    "lr = 5e-5\n",
    "prefix = \"fix homoglyphs: \"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")\n",
    "\n",
    "mtt_params = {\n",
    "    'device': device,\n",
    "    'dataset': HomoglyphDataset,\n",
    "    'model': model,\n",
    "    'tokenizer': tokenizer,\n",
    "    'optimizer': torch.optim.Adam,\n",
    "    'prefix': prefix,\n",
    "}\n",
    "\n",
    "fit_params = {\n",
    "    'x_train': x_train,\n",
    "#     'train_mask': train_mask,\n",
    "    'y_train': y_train,\n",
    "    'x_train_val': x_valid,\n",
    "#     'valid_mask': valid_mask,\n",
    "    'y_train_val': y_valid,\n",
    "    'epochs': epochs,\n",
    "    'learning_rate': lr,\n",
    "    'batch_size': batch_size,\n",
    "    'early_stopping_patience': early_stop,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "oddgHsNThru7"
   },
   "outputs": [],
   "source": [
    "mtt = M2T(**mtt_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "K5a_88n6htDG",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10: 100%|██████████| 55454/55454 [2:34:43<00:00,  5.97it/s, loss_train=0.05]   \n",
      "Epoch: 2/10:   0%|          | 1/55454 [00:00<2:36:59,  5.89it/s, loss_train=0.003]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------loss_valid=0.001\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^new best model^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10: 100%|██████████| 55454/55454 [2:27:06<00:00,  6.28it/s, loss_train=0.002]  \n",
      "Epoch: 3/10:   0%|          | 1/55454 [00:00<2:14:14,  6.88it/s, loss_train=0.001]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------loss_valid=0.0\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^new best model^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10: 100%|██████████| 55454/55454 [2:26:50<00:00,  6.29it/s, loss_train=0.001]  \n",
      "Epoch: 5/10:   0%|          | 0/55454 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------loss_valid=0.0\n",
      "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^new best model^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10:  27%|██▋       | 15054/55454 [39:55<1:47:09,  6.28it/s, loss_train=0]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-3adbc2d7b8af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmtt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-91a090cea181>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, x_train_val, y_train_val, epochs, learning_rate, batch_size, early_stopping_patience)\u001b[0m\n\u001b[1;32m     62\u001b[0m         ).loss\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m             )\n\u001b[0;32m--> 521\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         )\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    287\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 289\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    290\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    767\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    768\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 769\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    770\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mtt.fit(**fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "LVCvAHNhhvVf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py:2618: UserWarning: Moving the following attributes in the config to the generation config: {'max_length': 256}. You are seeing this warning because you've set generation parameters in the model config, as opposed to in the generation config.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('model/trained/tokenizer_config.json',\n",
       " 'model/trained/special_tokens_map.json',\n",
       " 'model/trained/vocab.json',\n",
       " 'model/trained/merges.txt',\n",
       " 'model/trained/added_tokens.json',\n",
       " 'model/trained/tokenizer.json')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtt.best_model.save_pretrained('model/trained/')\n",
    "tokenizer.save_pretrained('model/trained/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ZZIhZ8KQh15k"
   },
   "outputs": [],
   "source": [
    "# Проверка на наличие омоглифов в строке\n",
    "def checkHomoglyphs(output, target, glyphs):\n",
    "  count = 0\n",
    "  list_index = get_index(target, glyphs)\n",
    "  for c in list_index:\n",
    "    for glyph in glyphs[target[c]]:\n",
    "      if glyph in output:\n",
    "        count += 1\n",
    "        break\n",
    "  return count\n",
    "\n",
    "def evaluate(model, dataset, checkGlyphs=False, checkIncorrect=False, prefix=\"\"):\n",
    "    accuracy = 0\n",
    "    homoglyphs = 0 if checkGlyphs else 'not checked'\n",
    "    levenshtein = []\n",
    "    incorrect = []\n",
    "\n",
    "    for sentence in tqdm(dataset):\n",
    "      pred = predict(model, sentence[0], prefix=prefix)[0]\n",
    "      levenshtein.append(ratio(sentence[1], pred))\n",
    "      dot_error = sentence[1] == pred[:-1] or sentence[1][:-1] == pred\n",
    "\n",
    "      if(pred == sentence[1] or dot_error):\n",
    "        accuracy += 1\n",
    "      elif(checkIncorrect):\n",
    "        incorrect.append([sentence[1], sentence[0], pred])\n",
    "        # print(f'Original line:   {sentence[1]}')\n",
    "        # print(f'With homoglyphs: {sentence[0]}')\n",
    "        # print(f'Prediction:      {pred}')\n",
    "        # print()\n",
    "        if(checkGlyphs):\n",
    "          homoglyphs += checkHomoglyphs(pred, sentence[1], glyphs)\n",
    "\n",
    "    print()\n",
    "    print(f'Accuracy: {accuracy/len(dataset)}')\n",
    "    print(f'Levenshtein ratio: {np.mean(levenshtein)}')\n",
    "    print(f'Amount of homoglyphs: {homoglyphs}')\n",
    "\n",
    "    return incorrect\n",
    "\n",
    "def predict(model, x, prefix=\"fix homoglyphs: \"):\n",
    "    encodings = tokenizer(prefix + x, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "      generated_tokens = model.generate(**encodings)\n",
    "    answer = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
    "    return answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['The place or point of union  meeting or junction; specifically the place where two or more iíṇęṡ ọḟ ʀаі1ẉąȳ ṃẹėț ȯṟ сṛ0ṣʂ.',\n",
       "  'The place or point of union  meeting or junction; specifically the place where two or more lines of railway meet or cross.'],\n",
       " ['IN AN ACCENTUⱭ1 ṂÀŅṈȨⱤ; ΙṆ ΑСÇƠƦƉАṄĆĘ ᴡꞮΤḤ ĄĊƇẸŃȚ.',\n",
       "  'IN AN ACCENTUAL MANNER; IN ACCORDANCE WITH ACCENT.'],\n",
       " ['Relatinɢ ṭỏ  ọʀ çȯṇṫàīṅỉńǥ ṟưḃɓię.', 'Relating to  or containing rubble.'],\n",
       " ['AGGREGATE LENGTH OR DISTANCE IN MILES; ESP.  THE SUM OF LENGTHS OF TRACKS OR WIRES OF A RAILROAD COMPANY ΤȨ1ĘǤŖÀƤḤ ÇȮМǷΑŃУ ẸȚĆ.',\n",
       "  'AGGREGATE LENGTH OR DISTANCE IN MILES; ESP.  THE SUM OF LENGTHS OF TRACKS OR WIRES OF A RAILROAD COMPANY TELEGRAPH COMPANY ETC.'],\n",
       " ['Of  pertaining to or designating a complex organic acid produced as a white crystalline substance by the action of nitrous aćỉḏ ơṇ ɦʏḍɾỏʠųìṅọńе.',\n",
       "  'Of  pertaining to or designating a complex organic acid produced as a white crystalline substance by the action of nitrous acid on hydroquinone.'],\n",
       " ['TO CAUSE TO REMAIN IN A GIVEN SITUATION OR CONDITION; TO MAIṄΤÀΙŃ ŪΝÇḨΑПɢЕĎ; ȚȮ Ɦ01Ɗ ΟⱤ ΡƦȨṢĘṞṾẸ ꞮŅ АṈΥ ꟅṬĄṪĖ ƠṚ ŢΕṆỎŖ.',\n",
       "  'TO CAUSE TO REMAIN IN A GIVEN SITUATION OR CONDITION; TO MAINTAIN UNCHANGED; TO HOLD OR PRESERVE IN ANY STATE OR TENOR.'],\n",
       " [\"Clay  or potter's earth; sometimes pure clay or aluminɑ. Ѕėе С1àỿ.\",\n",
       "  \"Clay  or potter's earth; sometimes pure clay or alumina. See Clay.\"],\n",
       " ['A military station; the place at which a soldier or a body of troops is stаƫìοņеḏ; ąișᴏ  țẖȩ ṭɼơỏṗṡ ạṫ ṣụçḥ ɑ ʂţàƫíọṉ.',\n",
       "  'A military station; the place at which a soldier or a body of troops is stationed; also  the troops at such a station.'],\n",
       " ['To cause to grievȩ; ţȯ ɑḟƒ1іćƫ.', 'To cause to grieve; to afflict.'],\n",
       " ['INFERTILE; BARREN; UNPROFITABLЕ; ƯŃǷṚΟḌŲСṪÍṾȨ.',\n",
       "  'INFERTILE; BARREN; UNPROFITABLE; UNPRODUCTIVE.']]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[200100:200110]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"fix homoglyphs: \"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = T5ForConditionalGeneration.from_pretrained('model/trained')\n",
    "tokenizer = AutoTokenizer.from_pretrained('model/trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Relating to  or containing rubble.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "model.to(device)\n",
    "s = 'Relatinɢ ṭỏ  ọʀ çȯṇṫàīṅỉńǥ ṟưḃɓię.'\n",
    "predict(model, s, prefix=prefix)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE ABYSSINIAN OR ARABIAN IBEX (CAPRA NUBIANA). IT IS PROBABLY THE WILD GOAT OF THE BIBLE.\n",
      "THE ABYSSINIAN OR ARABIAN IBEX (CAPRA NUBIANA). IT IS PROBABLY THE WILD GOAT OF THE BIBLE.\n",
      "THE ABYSSINIAN OR ARABIAN IBEX (CAPRA NUBIANA). IT ÍꟅ ṔƦỌƁĄΒ1У ŢḤΕ ẆΙIḌ ǴȮẠΤ 0Ḟ ȚⱧЕ ƄꞮḆ1Ȩ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Crowded with business or activities; -- said of places and times; as  a busy street.\n",
      "Crowded with business or activities; -- said of places and times; as  a busy street.\n",
      "Crowded with business or activities; -- said of places aпԁ ṭíɱẹș; аṡ  ą ḃưṣʏ ʂṫṟėеţ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Any neuropterous insect of the genus Mantispa  and allied genera. The larvae feed on plant lice. Also used adjectively. See Illust. under Neuroptera.\n",
      "Any neuropterous insect of the genus Mantispa  and allied genera. The larvae feed on plant lice. Also used adjectively. See Illust. under Neuroptera.\n",
      "Any neuropterous insect of the genus Mantispa  and allied genera. The larvae feed on plant lice. Also used adjectively. See Illuṡţ. ųńɗėṟ Ņеūṛοƿƫȩɾà.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "ANY SPECIES OF THE GENUS MANIS  OR FAMILY MANIDAE.\n",
      "ANY SPECIES OF THE GENUS MANIS  OR FAMILY MANIDAE.\n",
      "ANY SPECÍĖЅ ȮḞ ȚꞪΕ ɢЕṆŲȘ МΑṄΙṠ  0Ŗ ƑАṂꞮ1У ṀĄŃĪḎẠȨ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "One who speaks several languages.\n",
      "One who speaks several languages.\n",
      "One who speaks sevеɼą1 iạńġưɑɡȩṡ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "A SUM OR STOCK OF WORDS EMPLOYED.\n",
      "A SUM OR STOCK OF WORDS EMPLOYED.\n",
      "A SUM OR ЅȚƠĆК ỎƑ ⱲỌƦḌȘ ΕṂƤ1ȮȲЕƉ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "To procrastinate.\n",
      "To procrastinate.\n",
      "To procrașţɪńàƫе.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "The irritating action of various agents (stimuli) on muscles  nerves or a sensory end organ by which activity is evoked; especially the nervous impulse produced by various agents on nerves or a sensory end organ by which the part connected with the nerve is thrown into a state of activity; irritation.\n",
      "The irritating action of various agents (stimuli) on muscles  nerves or a sensory end organ by which activity is evoked; especially the nervous impulse produced by various agents on nerves or a sensory end organ by which the part connected with the nerve is thrown into a state of activity; irritation.\n",
      "The irritating action of various agents (stimuli) on muscles  nerves or a sensory end organ by which activity is evoked; especially the nervous impulse produced by various agents on nerves or a sensory end organ by which the part connected with the nerve is thrown into a state of activíţʏ; іɼʀɪƫạțīơń.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "LIKE OR PERTAINING TO THE LEUCOSOIDEA  A TRIBE OF MARINE CRABS INCLUDING THE BOX CRAB OR CALAPPA.\n",
      "LIKE OR PERTAINING TO THE LEUCOSOIDEA  A TRIBE OF MARINE CRABS INCLUDING THE BOX CRAB OR CALAPPA.\n",
      "LIKE OR PERTAINING TO THE LEUCOSOIDEA  A TRIBE OF MARINE CRABS INCLUDING THE BOХ ƇṚΑḆ ƠŖ СА1ĄΡṖẠ.\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Something intended to serve  or that may serve as a pattern of something to be made; a material representation or embodiment of an ideal; sometimes a drawing; a plan; as the clay model of a sculpture; the inventor's model of a machine.\n",
      "Something intended to serve  or that may serve as a pattern of something to be made; a material representation or embodiment of an ideal; sometimes a drawing; a plan; as the clay model of a sculpture; the inventor's model of a machine.\n",
      "Something intended to serve  or that may serve as a pattern of something to be made; a material representation or embodiment of an ideal; sometimes a drawing; a plan; as the clay model of a sculpture; the inventoʀ'ṡ ṁοԁẹ1 ᴏḟ ą ḿạċһíпė.\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "c = 40000\n",
    "for i in range(10):\n",
    "    print(y_test[c + i])\n",
    "    print(predict(model, x_test[c + i], prefix=prefix)[0])\n",
    "    print(x_test[c + i])\n",
    "    print('-'*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['DIMINISHED IN VALUE; DISHONOⱤЕƉ; ĎȨǤƦⱭƊĘḎ.',\n",
       "        'DIMINISHED IN VALUE; DISHONORED; DEGRADED.'],\n",
       "       ['THE QUANTITY OR NUMBER WHICH FIL1Ṡ Ą ΤⱤẸĖ.',\n",
       "        'THE QUANTITY OR NUMBER WHICH FILLS A TREE.'],\n",
       "       ['To inhạƅɪț ɑ ʂһàņṭʏ.', 'To inhabit a shanty.'],\n",
       "       ...,\n",
       "       ['ONE WHO TREATS DISEASES OF THE HANDS AND FEET; ESPECIA1IỴ  0ΝЕ ᴡḤΟ ṞȨṂƠṾĘṠ ÇỎṚПṢ ẠŅƉ ΒƯṈÍỌṆꟅ.',\n",
       "        'ONE WHO TREATS DISEASES OF THE HANDS AND FEET; ESPECIALLY  ONE WHO REMOVES CORNS AND BUNIONS.'],\n",
       "       ['A framework moving on casters  designed to support children while learniṅɡ ṫ0 ⱳạ1ḵ.',\n",
       "        'A framework moving on casters  designed to support children while learning to walk.'],\n",
       "       ['Consisting of salt  or containing salt; as saline particles; saline substances; a saline ċаțɦąṛṭіƈ.',\n",
       "        'Consisting of salt  or containing salt; as saline particles; saline substances; a saline cathartic.']],\n",
       "      dtype='<U400')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/test.pkl', 'rb') as file:\n",
    "    test = pickle.load(file)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_aOi_QuSiIFj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 983/1000 [24:37<00:24,  1.47s/it]"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "# data = np.stack((x_test, y_test), axis=1)\n",
    "result = evaluate(model.to(device), test[70000:71000], checkGlyphs=False, checkIncorrect=True, prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.stack((x_test, y_test), axis=1)\n",
    "with open('data/test.pkl', 'wb') as file:\n",
    "    pickle.dump(test, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sortByType(incorrect):\n",
    "  output = {\n",
    "      'inaccurate': [],\n",
    "      'destroying': [],\n",
    "      'minor': [],\n",
    "  }\n",
    "\n",
    "  for sentence in incorrect:\n",
    "    levenshtein = ratio(sentence[0], sentence[2])\n",
    "\n",
    "    if(levenshtein >= 0.97):\n",
    "      output['minor'].append([sentence[0], sentence[1], sentence[2]])\n",
    "    elif(levenshtein >= 0.8):\n",
    "      output['inaccurate'].append([sentence[0], sentence[1], sentence[2]])\n",
    "    elif(levenshtein < 0.8):\n",
    "      output['destroying'].append([sentence[0], sentence[1], sentence[2]])\n",
    "\n",
    "  return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 6, 0, 22)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers = sortByType(result)\n",
    "len(result), len(answers['inaccurate']), len(answers['destroying']), len(answers['minor'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['ONE WHO LIBELS; ONE WHO INSTITUTES A SUIT IN AN ECCLESIASTICAL OR ADMIRALTY COURT.',\n",
       "  'ONE WHO LIBELS; ONE WHO INSTITUTES A SUIT IN AN ECCLESIASTICAL OR ADMIRAIṪΥ СΟŲⱤŢ.',\n",
       "  'ONE WHO LIBELS; ONE WHO INSTITUTES A SUIT IN AN ECCLESIASTICAL OR ADMIRAITY COURT.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['A name given to a numerous family of brass wind instruments with valves  invented by Antoine Joseph Adolphe Sax (known as Adolphe Sax) of Belgium and Paris and much used in military bands and in orchestras.',\n",
       "  'A name given to a numerous family of brass wind instruments with valves  invented by Antoine Joseph Adolphe Sax (known as Adolphe Sax) of Belgium and Paris and much used in military bands and iņ ᴏɼçɦȩʂƫʀąѕ.',\n",
       "  'A name given to a numerous family of brass wind instruments with valves  invented by Antoine Joseph Adolphe Sax (known as Adolphe Sax) of Belgium and Paris and much used in military bands and in orchestra.',\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " ['A round piece of timber at the bow or stern of a whaleboat  around which the harpoon lone is run out when the whale darts off.',\n",
       "  'A round piece of timber at the bow or stern of a whaleboat  around whicɦ țһȩ ẖạɼṗọȯṉ 10ṇę íʂ ʀưṅ οųṭ ⱳḥẹń ṫⱨė ᴡḩɑiе ḏàṟţѕ ᴏḟƒ.',\n",
       "  'A round piece of timber at the bow or stern of a whaleboat  around which the harpoon line is run out when the whale darts off.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['TO BE MULTIPLIED BY FOUR; TO INCREASE FOURFOLD; TO BECOME FOUR TIMES AS MUCH.',\n",
       "  'TO BE MULTIPLIED BY FOUR; TO INCREASE FOURFOIḎ; ΤȮ ḄЕĊ0ḾȨ ḞΟŪƦ ȚꞮⱮĘȘ ẠṠ МỤƇΗ.',\n",
       "  'TO BE MULTIPLIED BY FOUR; TO INCREASE FOURFOID; TO BECOME FOUR TIMES AS MUCH.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['COLD-BLOODED', 'COLD-BIΟƠƊΕḎ', 'COLD-BIOODED', 0.92, 0.92, 0.92],\n",
       " ['The emblem of the generative power in nature  carried in procession in the Bacchic orgies or worshiped in various ways.',\n",
       "  'The emblem of the generative power in nature  carried in procession in the Bacchic orgiеꜱ οɾ ⱳᴏŗșẖíрȩď іņ ᴠаɽɪơưṡ ᴡąỿṣ.',\n",
       "  'The emblem of the generative power in nature  carried in procession in the Bacchic orgles or worshiped in various ways.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['THE ACT OF PERCEIVING OR TASTING BY THE ORGANS OF TASTE; THE FACULTY OR SENSE BY WHICH WE PERCEIVE OR DISTINGUISH SAVORS.',\n",
       "  'THE ACT OF PERCEIVING OR TASTING BY THE ORGANS OF TASTE; THE FACUIṬΥ 0Ŗ ṠĖṈṢΕ ḄỴ ᴡꞪỈĆΗ ẈЕ ƤȨⱤĊĘÌṾẸ ΟƦ ḌÍꟅṪΙṆǴŲꞮЅḤ ȘАṾƠṞṠ.',\n",
       "  'THE ACT OF PERCEIVING OR TASTING BY THE ORGANS OF TASTE; THE FACUITY OR SENSE BY WHICH WE PERCEIVE OR DISTINGUISH SAVORS.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['A periodical increase of violence in a disease  as in remittent or continious fever; an increased energy of diseased and painful action.',\n",
       "  'A periodical increase of violence in a disease  as in remittent or continiȯūѕ ƒȩᶌęɽ; ɑп īņćɼẹàꜱėḏ еṉȩʀǵỵ 0ḟ ḍỉșęаṡẹɖ ąṇď ƿạìṅƒᴜi ɑċṭíοń.',\n",
       "  'A periodical increase of violence in a disease  as in remittent or continuous fever; an increased energy of diseased and painful action.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['AN AMMONITE; -- SO CALLED FROM ITS FORM  WHICH RESEMBLES THAT OF A COILED SNAKE.',\n",
       "  'AN AMMONITE; -- SO CALLED FROM ITS FORM  WHICH RESEMBLES THAT OF A COI1ĖḎ ȘṆАΚΕ.',\n",
       "  'AN AMMONITE; -- SO CALLED FROM ITS FORM  WHICH RESEMBLES THAT OF A COLLED SNAKE.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['ONE TO WHOM THE CHARGE OF THE PERSON OR ESTATE OF ANOTHER  AS OF A LUNATIC IS COMMITTED BY SUITABLE AUTHORITY; A GUARDIAN.',\n",
       "  'ONE TO WHOM THE CHARGE OF THE PERSON OR ESTATE OF ANOTHER  AS OF A LUNATIC IS COMMITTED BY SUITABLE AUTH0ṞÌȚȲ; Α ꞬƯАṚḌÍĄŃ.',\n",
       "  'ONE TO WHOM THE CHARGE OF THE PERSON OR ESTATE OF ANOTHER  AS OF A LUNATIC IS COMMITTED BY SUITABLE AUTHORITY; A QUARDIAN.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['The whole class of divinities to whom the name Baal was applied.',\n",
       "  'The whole class of divinities to whom thẹ ńаḿė Ḃąạ1 ⱳɑʂ àрṗiìеԁ.',\n",
       "  'The whole class of divinities to whom the name Bal was applied.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['A BOAT FOR CONVEYING PROVISIONS  TOOLS ETC.; -- SO CALLED BY MAINE LUMBERMEN.',\n",
       "  'A BOAT FOR CONVEYING PROVISIONS  TOOIṠ ĖΤƇ.; -- ṢƠ СÀ1IΕƊ ḄȲ ⱮΑꞮŅЕ 1ỤМḂȨⱤṂĘṈ.',\n",
       "  'A BOAT FOR CONVEYING PROVISIONS  TOOIS ETC.; -- SO CALLED BY MAINE LUMBERMEN.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['HAPPENING AT A SOLSTICE; ESP. (WITH REFERENCE TO THE NORTHERN HEMISPHERE)  HAPPENING AT THE SUMMER SOLSTICE OR MIDSUMMER.',\n",
       "  'HAPPENING AT A SOLSTICE; ESP. (WITH REFERENCE TO THE NORTHERN HEMISPHERE)  HAPPENING AT THE SUMMER SOIṢṬÌƇΕ 0Ṛ ⱮÍḌꟅŪМṂЕŖ.',\n",
       "  'HAPPENING AT A SOLSTICE; ESP. (WITH REFERENCE TO THE NORTHERN HEMISPHERE)  HAPPENING AT THE SUMMER SOISTICE OR MIDSUMMER.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['THE ACT OF MAKING SATISFACTION OR ATONEMENT FOR ANY CRIME OR FAULT; THE EXTINGUISHING OF GUILT BY SUFFERING OR PENALTY.',\n",
       "  'THE ACT OF MAKING SATISFACTION OR ATONEMENT FOR ANY CRIME OR FAULT; THE ΕẊΤÍŃǴỤΙЅꞪꞮΝĠ 0Ƒ ꞬƯĪIȚ ḂỴ ȘŲḞƑЕƦỈПɢ ΟṞ ṔȨŅⱭ1ṬỾ.',\n",
       "  'THE ACT OF MAKING SATISFACTION OR ATONEMENT FOR ANY CRIME OR FAULT; THE EXTINGUISHING OF QUILT BY SUFFERING OR PENALTY.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['Inconcocted.', 'Inconcoçţеḍ.', 'Inconcocated.', 0.96, 0.96, 0.96],\n",
       " ['A WOMAN WHO WAILS.',\n",
       "  'A WOMAN WHO WAI1Ș.',\n",
       "  'A WOMAN WHO WALLS.',\n",
       "  0.94,\n",
       "  0.94,\n",
       "  0.94],\n",
       " ['TO WRITE \"\"\"\" QUERY\"\"\"\" (QU.  QY. OR ?) AGAINST AS A DOUBTFUL SPELLING OR SENSE IN A PROOF. SEE QUAERE.',\n",
       "  'TO WRITE \"\"\"\" QUERY\"\"\"\" (QU.  QY. OR ?) AGAINST AS A DOUBTFUL SPELLING OR SENSE IN Α ǷⱤ0ΟḞ. ЅΕЕ ꞬŪАȨƦĘ.',\n",
       "  'TO WRITE \"\"\"\" QUERY\"\"\"\" (QU.  QY. OR?) AGAINST AS A DOUBTFUL SPELLING OR SENSE IN A PROOF. SEE QUAERE.',\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0],\n",
       " ['Same as Amercement.',\n",
       "  'Saṁȩ ɑṣ Ąḿęɾćẹɱėńţ.',\n",
       "  'Same as Americant.',\n",
       "  0.86,\n",
       "  0.86,\n",
       "  0.86],\n",
       " ['The chiff-chaff.',\n",
       "  'The chiƒḟ-ċḩąƒḟ.',\n",
       "  'The chief-chaff.',\n",
       "  0.94,\n",
       "  0.94,\n",
       "  0.94],\n",
       " ['Same as Mollemoke.',\n",
       "  'Same as Ḿο1iėɱᴏķе.',\n",
       "  'Same as Molemoke.',\n",
       "  0.97,\n",
       "  0.97,\n",
       "  0.97],\n",
       " ['One of the whorls of a spiral univalve shell.',\n",
       "  'One of the whoriṡ ȯḟ ạ ṣṗɪɼɑ1 ụṉīᶌàiⱱȩ ʂⱨę1i.',\n",
       "  'One of the whoris of a spiral univalve shell.',\n",
       "  0.98,\n",
       "  0.98,\n",
       "  0.98],\n",
       " ['DESTITUTE OR DEPRIVED OF THE FACULTY OF SPEECH.',\n",
       "  'DESTITUTE OR DEPRIVED OF THE FACUIṪʏ ỌḞ ЅΡȨĘƇḤ.',\n",
       "  'DESTITUTE OR DEPRIVED OF THE FACUITY OF SPEECH.',\n",
       "  0.98,\n",
       "  0.98,\n",
       "  0.98],\n",
       " ['Flat at the anterior and concave at the posterior end; -- said of the centra of the vertebrae of some extinct dinouaurs.',\n",
       "  'Flat at the anterior and concave at the posterior end; -- said of the centra of the vertebrae of some extinct dinỏưàųʀʂ.',\n",
       "  'Flat at the anterior and concave at the posterior end; -- said of the centra of the vertebrae of some extinct dinouairs.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['Small; little; insignificant; mean; -- Same as Petty.',\n",
       "  'Small; little; insignificant; ɱȩàṇ; -- Șамę ąṡ Ƥẹţƫʏ.',\n",
       "  'Small; little; insignificant; mean; -- Same as Pety.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['Employing too many words; diffuse.',\n",
       "  'Empiơȳīṉɢ ţỏọ ṃɑṇу ẉȯŗḍʂ; ɖỉƒḟᴜѕẹ.',\n",
       "  'Emplying too many words; diffuse.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99],\n",
       " ['SCARCELY; BARELY; NOT GUITE; NOT WHOLLY.',\n",
       "  'SCARCELY; BARELY; NƠΤ ꞬỤΙȚẸ; ṈỎṬ ᴡḤỌ1IУ.',\n",
       "  'SCARCELY; BARELY; NOT QUITE; NOT WHOLLY.',\n",
       "  0.97,\n",
       "  0.97,\n",
       "  0.97],\n",
       " ['TO ADORN WITH A DIADEM; TO CROWN.',\n",
       "  'TO ADORN WITH A DIÀḌẸⱮ; ṪȮ ĊⱤ0ẈŃ.',\n",
       "  'TO ADORN WITH A DLADEM; TO CROWN.',\n",
       "  0.97,\n",
       "  0.97,\n",
       "  0.97],\n",
       " ['Indeed ! in truth ! -- a term of asseveration said to have been derived from the practice of swearing by the Virgin Mary.',\n",
       "  'Indeed ! in truth ! -- a term of asseveration said to have been derived from the practice of swearing by the Ṿíɽġіṉ Ɱɑɼу.',\n",
       "  'Indeed! in truth! -- a term of asseveration said to have been derived from the practice of swearing by the Virgin Mary.',\n",
       "  0.99,\n",
       "  0.99,\n",
       "  0.99]]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "4 columns passed, passed data had 6 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 568\u001b[0;31m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    569\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[0;34m(content, columns)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;31m# caller's responsibility to check for this...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m             raise AssertionError(\n\u001b[0m\u001b[1;32m    693\u001b[0m                 \u001b[0;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 4 columns passed, passed data had 6 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-22529a13ee19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'original line'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'with homoglyphs'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'models predict'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'l-ratio'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    568\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mis_named_tuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m                     \u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m                     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# columns if columns is not None else []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         return _list_of_dict_to_arrays(\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36m_list_to_arrays\u001b[0;34m(data, columns, coerce_float, dtype)\u001b[0m\n\u001b[1;32m    569\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_object_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoerce_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoerce_float\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    570\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 571\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    572\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 4 columns passed, passed data had 6 columns"
     ]
    }
   ],
   "source": [
    "errors = pd.DataFrame(data=result, columns=['original line', 'with homoglyphs', 'models predict', 'l-ratio'])\n",
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['One who huddles things together.']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(model, 'One who huddleṡ ṭḩìṇǵṣ ṫȯġȩţɦęɼ.', prefix=prefix)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
