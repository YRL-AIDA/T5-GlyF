{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EY9Btz4Pa6e"
      },
      "outputs": [],
      "source": [
        "import enum\n",
        "import copy\n",
        "import pickle\n",
        "import random\n",
        "import requests\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm, trange\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from transformers import T5ForConditionalGeneration, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Dataset generation | Генерация датасета\n"
      ],
      "metadata": {
        "id": "rBS-w6eUwa_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание словаря омоглифов\n",
        "\n",
        "intentionals = dict()\n",
        "\n",
        "int_resp = requests.get(\"https://www.unicode.org/Public/security/latest/intentional.txt\", stream=True)\n",
        "for line in int_resp.iter_lines():\n",
        "  if len(line):\n",
        "    line = line.decode('utf-8-sig')\n",
        "    if line[0] != '#':\n",
        "      line = line.replace(\"#*\", \"#\")\n",
        "      _, line = line.split(\"#\", maxsplit=1)\n",
        "      if line[3] not in intentionals:\n",
        "        intentionals[line[3]] = []\n",
        "      intentionals[line[3]].append(line[7])"
      ],
      "metadata": {
        "id": "H3q8nd7Uwd2a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fairseq\n",
        "!pip install textdistance\n",
        "!pip install pyarrow\n",
        "!pip install sacremoses\n",
        "!pip install fastBPE\n",
        "!pip install subword_nmt"
      ],
      "metadata": {
        "id": "AcbANFNWwjXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from abc import ABC\n",
        "from typing import List, Tuple, Callable, Dict\n",
        "from fairseq.hub_utils import GeneratorHubInterface\n",
        "from scipy.optimize import NonlinearConstraint, differential_evolution\n",
        "from textdistance import levenshtein\n",
        "import pyarrow\n",
        "import sacremoses\n",
        "import fastBPE\n",
        "import subword_nmt"
      ],
      "metadata": {
        "id": "17rJn6XawpQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "en2fr = torch.hub.load('pytorch/fairseq',\n",
        "                       'transformer.wmt14.en-fr',\n",
        "                       tokenizer='moses',\n",
        "                       bpe='subword_nmt').to(device)"
      ],
      "metadata": {
        "id": "p0_KD0tLwsY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Objective(ABC):\n",
        "  \"\"\" Abstract class representing objectives for scipy's genetic algorithms.\"\"\"\n",
        "\n",
        "  def __init__(self, model: GeneratorHubInterface, input: str, max_perturbs: int, distance: Callable[[str,str],int]):\n",
        "    if not model:\n",
        "      raise ValueError(\"Must supply model.\")\n",
        "    if not input:\n",
        "      raise ValueError(\"Must supply input.\")\n",
        "\n",
        "    self.model: GeneratorHubInterface = model\n",
        "    self.input: str = input\n",
        "    self.max_perturbs: int = max_perturbs\n",
        "    self.distance: Callable[[str,str],int] = distance\n",
        "    self.output = self.model.translate(self.input)\n",
        "\n",
        "  def objective(self) -> Callable[[List[float]], float]:\n",
        "    def _objective(perturbations: List[float]) -> float:\n",
        "      candidate: str = self.candidate(perturbations)\n",
        "      translation: str = self.model.translate(candidate)\n",
        "      return -self.distance(self.output, translation)\n",
        "    return _objective\n",
        "\n",
        "  def differential_evolution(self, print_result=True, verbose=True, maxiter=60, popsize=32, polish=False) -> str:\n",
        "    result = differential_evolution(self.objective(), self.bounds(),\n",
        "                                    disp=verbose, maxiter=maxiter,\n",
        "                                    popsize=popsize, polish=polish)\n",
        "    candidate = self.candidate(result.x)\n",
        "    if (print_result):\n",
        "      print(f\"Result: {candidate}\")\n",
        "      print(f\"Result Distance: {result.fun}\")\n",
        "      print(f\"Perturbation Encoding: {result.x}\")\n",
        "      print(f\"Input Translation: {self.output}\")\n",
        "      print(f\"Result Translation: {self.model.translate(candidate)}\")\n",
        "    return candidate\n",
        "\n",
        "  def bounds(self) -> List[Tuple[float, float]]:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "  def candidate(self, perturbations: List[float]) -> str:\n",
        "    raise NotImplementedError()\n",
        "\n",
        "\n",
        "def natural(x: float) -> int:\n",
        "    \"\"\"Rounds float to the nearest natural number (positive int)\"\"\"\n",
        "    return max(0, round(float(x)))"
      ],
      "metadata": {
        "id": "Hbwzuw4iwuOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HomoglyphObjective(Objective):\n",
        "\n",
        "  def __init__(self, model: GeneratorHubInterface, input: str, max_perturbs=None, distance: Callable[[str,str],int] = levenshtein.distance, homoglyphs: Dict[str,List[str]] = intentionals, **kwargs):\n",
        "    super().__init__(model, input, max_perturbs, distance)\n",
        "    if not self.max_perturbs:\n",
        "      self.max_perturbs = len(self.input)\n",
        "    self.homoglyphs = homoglyphs\n",
        "    self.glyph_map = []\n",
        "    for i, char in enumerate(self.input):\n",
        "      if char in self.homoglyphs:\n",
        "        charmap = self.homoglyphs[char]\n",
        "        charmap = list(zip([i] * len(charmap), charmap))\n",
        "        self.glyph_map.extend(charmap)\n",
        "\n",
        "  def bounds(self) -> List[Tuple[float, float]]:\n",
        "    return [(-1, len(self.glyph_map)-1)] * self.max_perturbs\n",
        "\n",
        "  def candidate(self, perturbations: List[float]) -> str:\n",
        "    candidate = [char for char in self.input]\n",
        "    for perturb in map(natural, perturbations):\n",
        "      if perturb >= 0:\n",
        "        i, char = self.glyph_map[perturb]\n",
        "        candidate[i] = char\n",
        "    return ''.join(candidate)"
      ],
      "metadata": {
        "id": "pRGAuBf_wwMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = open('jfleg.txt', 'r')\n",
        "text = f.read().split('\\n')\n",
        "data = []\n",
        "for s in text:\n",
        "  new_s = s.split(' ')[:4]\n",
        "  new_s.remove(',') if ',' in new_s else None\n",
        "  new_s.remove(\"'s\") if \"'s\" in new_s else None\n",
        "  data.append(\" \".join(new_s))"
      ],
      "metadata": {
        "id": "6PbvbYCYw1QO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = pd.read_csv('unigram_freq.csv')\n",
        "words = list(text['word'])\n",
        "start = int(len(words)*0.8) # избегаем самые частые слова вроде предлогов и союзов\n",
        "words = words[start:start+600]\n",
        "for w in words:\n",
        "  if len(w) > 4:\n",
        "    data.append(w)\n",
        "data = np.array(data)"
      ],
      "metadata": {
        "id": "wRHOTfEf5k21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "np.random.shuffle(data)\n",
        "len(data)"
      ],
      "metadata": {
        "id": "Yxh1BLkJ-nBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def experiment(model, objective, source, min_perturb, max_perturb, maxiter, popsize):\n",
        "  train = []\n",
        "  for i in trange(min_perturb, max_perturb, desc=\"Perturbations\"):\n",
        "    for sentence in tqdm(source, leave=False, desc=\"Sentences\"):\n",
        "      changed = objective(en2fr, sentence, max_perturbs=i).differential_evolution(print_result=False, verbose=False, maxiter=maxiter, popsize=popsize)\n",
        "      train.append((changed, sentence))\n",
        "  return train"
      ],
      "metadata": {
        "id": "RPyjJbIww-kW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min_perturb = 1 # минимальное количество вмешательств\n",
        "max_perturb = 5 # максимальное количество вмешательств\n",
        "maxiter = 3 # количество поколений\n",
        "popsize = 16 # размер популяции\n",
        "ds = experiment(en2fr, HomoglyphObjective, data, min_perturb, max_perturb, maxiter, popsize)\n",
        "\n",
        "with open('homoglyph.pkl', 'wb') as f:\n",
        "  pickle.dump(ds, f)"
      ],
      "metadata": {
        "id": "_wK028r3w_P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preparation for training | Подготовка к обучению"
      ],
      "metadata": {
        "id": "RiPT7_qRxL00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class AvailableCorrectors(enum.Enum):\n",
        "\n",
        "    sage_fredt5_large = \"ai-forever/sage-fredt5-large\"\n",
        "    sage_fredt5_distilled_95m = \"ai-forever/sage-fredt5-distilled-95m\"\n",
        "    sage_m2m100_1B = \"ai-forever/sage-m2m100-1.2B\"\n",
        "    sage_mt5_large = \"ai-forever/sage-mt5-large\"\n",
        "\n",
        "    m2m100_1B = \"ai-forever/RuM2M100-1.2B\"\n",
        "    m2m100_418M = \"ai-forever/RuM2M100-418M\"\n",
        "    fred_large = \"ai-forever/FRED-T5-large-spell\"\n",
        "    ent5_large = \"ai-forever/T5-large-spell\""
      ],
      "metadata": {
        "id": "Y8N1-GGOy6MP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_model = AvailableCorrectors.sage_fredt5_distilled_95m.value\n",
        "\n",
        "model = T5ForConditionalGeneration.from_pretrained(path_to_model)\n",
        "tokenizer = AutoTokenizer.from_pretrained(path_to_model)"
      ],
      "metadata": {
        "id": "X30s_qcaxPAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = sum(list(intentionals.values()), [])\n",
        "tokens = set(tokens) - set(tokenizer.vocab.keys())\n",
        "tokenizer.add_tokens(list(tokens))\n",
        "model.resize_token_embeddings(len(tokenizer))"
      ],
      "metadata": {
        "id": "Nm_MPN2ChW5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Если данные загружать из ранее сгенерированного файла\n",
        "with open('homoglyph.pkl', 'rb') as f:\n",
        "  ds = pickle.load(f)"
      ],
      "metadata": {
        "id": "uO7G1ZCFEVDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = np.array(ds)\n",
        "train_size = int(0.8*ds.shape[0])\n",
        "x_train = ds[:train_size, 0]\n",
        "y_train = ds[:train_size, 1]\n",
        "x_train_val = ds[train_size:, 0]\n",
        "y_train_val = ds[train_size:, 1]\n",
        "x_train.shape, x_train_val.shape"
      ],
      "metadata": {
        "id": "GKZEzCufhTES"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training | Обучение"
      ],
      "metadata": {
        "id": "EBfG3qwowT5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HomoglyphDataset(Dataset):\n",
        "\n",
        "    def __init__(self, X, y):\n",
        "        self.X = np.array(X)\n",
        "        self.y = np.array(y)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return (self.X[index], self.y[index])"
      ],
      "metadata": {
        "id": "r8nseuLKPh_K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class M2T():\n",
        "  def __init__(self, device, dataset,\n",
        "               model, tokenizer,\n",
        "               learning_rate, epochs,\n",
        "               batch_size, optimizer,\n",
        "               early_stopping_patience=10,\n",
        "               prefix=\"\"):\n",
        "\n",
        "    self.device = device\n",
        "    self.dataset = dataset\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "    self.learning_rate = learning_rate\n",
        "    self.epochs = epochs\n",
        "    self.batch_size = batch_size\n",
        "    self.optimizer = optimizer\n",
        "    self.early_stopping_patience = early_stopping_patience\n",
        "    self.prefix = prefix\n",
        "\n",
        "    self.best_model = copy.deepcopy(model)\n",
        "    self.train_loss = []\n",
        "    self.val_loss = []\n",
        "    self.best_val_loss = float('inf')\n",
        "    self.best_epoch = 0\n",
        "\n",
        "  def predict(self, x):\n",
        "    encodings = self.tokenizer(x, return_tensors=\"pt\").to(self.model.device)\n",
        "    if self.prefix == \"\":\n",
        "      generated_tokens = self.model.generate(\n",
        "          **encodings, forced_bos_token_id=tokenizer.get_lang_id(\"ru\"))\n",
        "    else:\n",
        "      generated_tokens = self.model.generate(**encodings)\n",
        "    answer = self.tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)\n",
        "    return answer\n",
        "\n",
        "  def plot_losses(self):\n",
        "    c_iter = range(len(self.train_loss))\n",
        "\n",
        "    fig = plt.figure()\n",
        "    ax = fig.gca()\n",
        "    ax.set_xticks(c_iter)\n",
        "    plt.plot(c_iter, self.train_loss, color='orange', label='train_loss')\n",
        "    plt.plot(c_iter, self.val_loss, color='blue', label='val_loss')\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Losses')\n",
        "    plt.savefig('losses.png')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "  def fit(self, x_train, y_train, x_train_val, y_train_val):\n",
        "\n",
        "    self.model.to(self.device)\n",
        "    optimizer = self.optimizer(self.model.parameters(), lr=self.learning_rate)\n",
        "\n",
        "    train = self.dataset(x_train, y_train)\n",
        "    val = self.dataset(x_train_val, y_train_val)\n",
        "\n",
        "    train = DataLoader(train, batch_size=self.batch_size, shuffle=True)\n",
        "    val = DataLoader(val, batch_size=self.batch_size, shuffle=False)\n",
        "\n",
        "    for epoch in range(self.epochs):\n",
        "      mean_loss = 0\n",
        "      batch_n = 0\n",
        "      self.model.train()\n",
        "\n",
        "      print(f'Epoch: {epoch}', end=' ---------------------- ')\n",
        "\n",
        "      for batch_i, (batch, target) in enumerate(train):\n",
        "        x = self.tokenizer([self.prefix + sentence for sentence in batch], return_tensors='pt', padding=True).to(model.device)\n",
        "        y = self.tokenizer(target, return_tensors='pt', padding=True).to(model.device)\n",
        "        y.input_ids[y.input_ids == 0] = -100\n",
        "\n",
        "        loss = self.model(\n",
        "            input_ids=x.input_ids,\n",
        "            attention_mask=x.attention_mask,\n",
        "            labels=y.input_ids,\n",
        "            decoder_attention_mask=y.attention_mask,\n",
        "            return_dict=True\n",
        "        ).loss\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        mean_loss += float(loss)\n",
        "        batch_n += 1\n",
        "\n",
        "      mean_loss /= batch_n\n",
        "      self.train_loss.append(mean_loss)\n",
        "      print(f'Loss_train: {round(mean_loss, 3)}', end=' ; ')\n",
        "\n",
        "      self.model.eval()\n",
        "      mean_loss = 0\n",
        "      batch_n = 0\n",
        "\n",
        "      with torch.no_grad():\n",
        "        for batch, target in val:\n",
        "            x = self.tokenizer(batch, return_tensors='pt', padding=True).to(model.device)\n",
        "            y = self.tokenizer(target, return_tensors='pt', padding=True).to(model.device)\n",
        "            y.input_ids[y.input_ids == 0] = -100\n",
        "\n",
        "            loss = self.model(\n",
        "                input_ids=x.input_ids,\n",
        "                attention_mask=x.attention_mask,\n",
        "                labels=y.input_ids,\n",
        "                decoder_attention_mask=y.attention_mask,\n",
        "                return_dict=True\n",
        "            ).loss\n",
        "\n",
        "            mean_loss += float(loss)\n",
        "            batch_n += 1\n",
        "\n",
        "      mean_loss /= batch_n\n",
        "      self.val_loss.append(mean_loss)\n",
        "      print(f'Loss_val: {round(mean_loss, 3)}')\n",
        "      if mean_loss < self.best_val_loss:\n",
        "        self.best_epoch = epoch\n",
        "        self.best_val_loss = mean_loss\n",
        "        self.best_model = copy.deepcopy(model)\n",
        "        print('New best model.')\n",
        "      elif epoch - self.best_epoch > self.early_stopping_patience:\n",
        "        print(f'Model has not improved in the last {self.early_stopping_patience} epochs. Break.')\n",
        "        break"
      ],
      "metadata": {
        "id": "RNHlKtBOPoyd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "epochs = 100\n",
        "early_stop = 10\n",
        "lr = 1e-3\n",
        "prefix = \"fix homoglyphs | \"\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "params = {\n",
        "    'device': device,\n",
        "    'dataset': HomoglyphDataset,\n",
        "    'model': model,\n",
        "    'tokenizer': tokenizer,\n",
        "    'epochs': epochs,\n",
        "    'learning_rate': lr,\n",
        "    'batch_size': batch_size,\n",
        "    'optimizer': torch.optim.Adam,\n",
        "    'early_stopping_patience': early_stop,\n",
        "    'prefix': prefix,\n",
        "}"
      ],
      "metadata": {
        "id": "uPRK9rjrUhgb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtt = M2T(**params)\n",
        "mtt.fit(x_train, y_train, x_train_val, y_train_val)"
      ],
      "metadata": {
        "id": "0eL3f3nXzuZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mtt.plot_losses()"
      ],
      "metadata": {
        "id": "2gsQtVvwlXU7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}